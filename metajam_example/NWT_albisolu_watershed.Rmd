---
title: "HBR_watershed_10"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


###Step 1: Load packages
```{r}

library(metajam)  
library(udunits2)
# For wrangling the data
library(readr)
library(tidyr)
library(dplyr)
library(purrr)
library(stringr)
library(metajam)
library(tidyverse) # for convenience
library(here) # for file path management
library(stringdist) # for first pass of naming-matching
library(vctrs) # for joining tables
library(readxl) # for reading the template excel sheet
install.packages("naniar")
library(naniar)

```


####Step 2: Find the link to the dataset
Go to the web address for the dataset and find the download button for the data. 

In our case the link is: https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-nwt.103.12&entityid=413c3eb5a1a52e3ce2f9e52b3565aadd

#### Step 3: Choose where you want the files to be saved
In our case, we'll just put it into the metajam_example folder.

```{r}

#eg desired_path_to_data <- "~/Desktop"
desired_path_to_data <- "~/SI_river_data"

# create the folder if it does not exist yet
dir.create(desired_path_to_data, showWarnings = FALSE)


```


#### Step 4: Download the data by pasting the link you just copied

```{r}


my_data_url <- "https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-nwt.103.12&entityid=413c3eb5a1a52e3ce2f9e52b3565aadd"

# this will download the data into a folder and save the path to that folder
downloaded_data <- download_d1_data(data_url = my_data_url, path = desired_path_to_data)

```


#### Step 5: Now read in the data (with all the metadata)

```{r}

my_data <- read_d1_files(downloaded_data)

albisolu_NWT_data <- my_data$data

my_data$attribute_metadata

```

###Step 6: data cleanup

```{r}


# I can see that the column Year_Month includes the info from the column in the template 'Sampling Date' so I want to rename that column 

names(albisolu_NWT_data) <- as.character(names(albisolu_NWT_data))

albisolu_NWT_data <- albisolu_NWT_data %>% 
  rename('Sampling Date' = 'date')

albisolu_NWT_data <- albisolu_NWT_data %>% 
  rename('Site/Stream Name' = 'local_site')

albisolu_NWT_data <- albisolu_NWT_data %>% 
  rename('LTER' = 'LTER_site')

albisolu_NWT_data <- albisolu_NWT_data %>% 
  rename('Time' = 'time')

albisolu_NWT_data <- albisolu_NWT_data %>% 
  rename('Conductivity' = 'cond')

albisolu_NWT_data <- albisolu_NWT_data %>% 
  rename('alkalinity' = 'alkal')

names(albisolu_NWT_data) <- gsub("[^0-9A-Za-z///' ]","", names(albisolu_NWT_data))

my_data$attribute_metadata

```



Read in template
```{r}

template <- read_excel(here("metajam_example", "Stream_Data_Template.xlsx"), 
                               sheet = "Raw Data",
                               col_types = "text"
                               ) %>%
  mutate(`Sampling Date` = as.Date(`Sampling Date`))


template <- template %>% 
  add_column('NOx' = '.', .before = "NO3")

```

Fuzzy match
```{r}

# Start by matching by closest name as a first pass. 
  # Note that we match the lower case names
  # Note that the weight i= 0.1 says that we will be more likely to match if watershed 1 = template + extra
(fuzzy_match <- tibble(template = names(template)) %>%
   mutate(watershed10 = names(albisolu_NWT_data)[amatch(tolower(template), tolower(names(albisolu_NWT_data)), maxDist = 1, weight = c(d=1,i=0.1,s=1,t=1))])
)


```

```{r}


# Fill in the columns that didn't match, and correct the wrongly corrected matches
# continue in the same way until you've filled out everything you could.
  # Note: NA_character_ is just NA but of the character type.
(lookup_table <- fuzzy_match %>%
  mutate(watershed10 = case_when(
    template %in% c("DIC", "NOx", "TKN", "PON") ~ NA_character_,
    TRUE ~ watershed10)))

lookup_table <- lookup_table %>%
  filter(!is.na(watershed10))

correct_colnames <- lookup_table$template

correct_colnames <- as.character(correct_colnames)

correct_colnames

```
Once the lookup table is as filled out as possible, we can remove all rows that still had no match.

```{r}


new_datatable_NWT_1 <- albisolu_NWT_data %>% 
        select(all_of(c(correct_colnames)))


```

```{r}




#Changing missing value codes for columns for which NP is the missing value code
new_datatable_NWT_1$alkalinity <- na_if(new_datatable_NWT_1$alkalinity, "NP")

new_datatable_NWT_1$DOC <- na_if(new_datatable_NWT_1$DOC, "NP")

new_datatable_NWT_1$TOC <- na_if(new_datatable_NWT_1$TOC, "NP")

new_datatable_NWT_1$TDN <- na_if(new_datatable_NWT_1$TDN, "NP")

new_datatable_NWT_1$TN <- na_if(new_datatable_NWT_1$TN, "NP")

new_datatable_NWT_1$DON <- na_if(new_datatable_NWT_1$DON, "NP")

new_datatable_NWT_1$NO3 <- na_if(new_datatable_NWT_1$NO3, "NP")

new_datatable_NWT_1$NH4 <- na_if(new_datatable_NWT_1$NH4, "NP")

new_datatable_NWT_1$PO4 <- na_if(new_datatable_NWT_1$PO4, "NP")

new_datatable_NWT_1$TDP <- na_if(new_datatable_NWT_1$TDP, "NP")

new_datatable_NWT_1$DOP <- na_if(new_datatable_NWT_1$DOP, "NP")

new_datatable_NWT_1$TP <- na_if(new_datatable_NWT_1$TP, "NP")

new_datatable_NWT_1$PP <- na_if(new_datatable_NWT_1$PP, "NP")

new_datatable_NWT_1$pH <- na_if(new_datatable_NWT_1$pH, "NP")

new_datatable_NWT_1$Si <- na_if(new_datatable_NWT_1$Si, "NP")

new_datatable_NWT_1$Na <- na_if(new_datatable_NWT_1$Na, "NP")

new_datatable_NWT_1$K <- na_if(new_datatable_NWT_1$K, "NP")

new_datatable_NWT_1$Ca <- na_if(new_datatable_NWT_1$Ca, "NP")

new_datatable_NWT_1$SO4 <- na_if(new_datatable_NWT_1$SO4, "NP")

new_datatable_NWT_1$TDP <- na_if(new_datatable_NWT_1$TDP, "NP")

#Changing missing value codes to NA for columns with alternate exisiting missing value codes

new_datatable_NWT_1$Time<- na_if(new_datatable_NWT_1$Time, "DNS")

new_datatable_NWT_1$NO3 <- na_if(new_datatable_NWT_1$NO3, "u")

new_datatable_NWT_1$TP <- na_if(new_datatable_NWT_1$TP, "u")

new_datatable_NWT_1$PP <- na_if(new_datatable_NWT_1$PP, "u")

new_datatable_NWT_1$DON <- na_if(new_datatable_NWT_1$DON, "EQCL")

new_datatable_NWT_1$DOP <- na_if(new_datatable_NWT_1$DOP, "EQCL")

#still trying to figure out how to do these numeric thresholds to input NAS
new_datatable_NWT_1 <- new_datatable_NWT_1 %>% 
 mutate(NH4 = ifelse(NH4 < 0.1428, "NA", NH4))



new_datatable_NWT_1 <- replace_with_na_all(data = new_datatable_NWT_1$NH4, condition = ~NH4 < 0.1428)



new_datatable_NWT_1 <- new_datatable_NWT_1 %>% 
 mutate(SO4 = ifelse(SO4 < 0.28, "NA", SO4))

new_datatable_NWT_1 <- new_datatable_NWT_1 %>% 
 mutate(TDP = ifelse(TDP < 0.0258, "NA", TDP))

#PN has a missing value code of u but that attribute is not in the new table


my_data$attribute_metadata

```

Loading the solute units template

```{r}


solute_units_Template <- read_excel(here("metajam_example", "Stream_Data_Template.xlsx"), sheet = "Solute Units" )

solute_units_Template <- solute_units_Template  %>%
  select(Measurement, Unit)


```

Making a dataframe from the attribute metadata that only inlcudes the columns I need to match the template (attributeName and units)
```{r}

attributes <- data.frame(my_data$attribute_metadata)

attributes <- attributes  %>%
  select(attributeName, unit)

#Changing some attribute names so that they are easier to match

attributes$attributeName <- gsub("cond", "Conductivity", attributes$attributeName)

attributes$attributeName <- gsub("alkal", "Alkalinity", attributes$attributeName)

#Remove ionic notations
attributes$attributeName <- gsub("[^0-9A-Za-z///' ]"," ", attributes$attributeName)

```



Fuzzy matching template solute units table to attribute table
```{r}

(fuzzy_match <- tibble(solute_units_Template$Measurement) %>%
   mutate(watershed_units_10 = attributes$attributeName[amatch(tolower(solute_units_Template$Measurement), tolower(attributes$attributeName), maxDist = 1, weight = c(d=1,i=0.1,s=1,t=1))])
)


```


```{r}


# Fill in the columns that didn't match, and correct the wrongly corrected matches
# continue in the same way until you've filled out everything you could.
  # Note: NA_character_ is just NA but of the character type.
(lookup_table_units <- fuzzy_match %>%
  mutate(watershed_units_10 = case_when(
    solute_units_Template$Measurement %in% c("DIC","DO", "DO%","PON", "TKN") ~ NA_character_,
    TRUE ~ watershed_units_10)))

#Make a string of the correct names
correct_names <- lookup_table_units$'solute_units_Template$Measurement'


```

```{r}

#Make a table that matches the template
solute_units_table_new <- attributes %>% 
        filter(attributeName %in% c(correct_names))

solute_units_table_new  %>% 
  rename(Measurement = attributeName, Unit = unit)

```




