---
title: "ADC_Toolik_duplicates"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

###Step 1: Load packages

```{r}

library(metajam)  
library(udunits2)
# For wrangling the data
library(readr)
library(tidyr)
library(dplyr)
library(purrr)
library(stringr)
library(metajam)
library(tidyverse) # for convenience
library(here) # for file path management
library(stringdist) # for first pass of naming-matching
library(vctrs) # for joining tables
library(readxl) # for reading the template excel sheet
library(openxlsx) #for writing the excel file
library(expss)

```

####Step 2: Find the link to the dataset
Go to the web address for the dataset and find the download button for the data. 

In our case the link is: https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-arc.10303.6&entityid=bbc1cb59633df57380d997726916180a

#### Step 3: Choose where you want the files to be saved
In our case, we'll just put it into the metajam_example folder.

```{r}

#eg desired_path_to_data <- "~/Desktop"
desired_path_to_data <- "~/SI_river_data"

# create the folder if it does not exist yet
dir.create(desired_path_to_data, showWarnings = FALSE)


```

#### Step 4: Download the data by pasting the link you just copied
```{r}

my_data_url <- "https://portal.edirepository.org/nis/dataviewer?packageid=knb-lter-arc.10303.6&entityid=bbc1cb59633df57380d997726916180a"

# this will download the data into a folder and save the path to that folder
downloaded_data <- download_d1_data(data_url = my_data_url, path = desired_path_to_data)


```

#### Step 5: Now read in the data (with all the metadata)

```{r}


my_data <- read_d1_files(downloaded_data, na = c("-888.88", "-888.888", "-888", "-999", "-9999"))

Toolik_watershed_data <- my_data$data

#remove 2nd and 3rd rows which were empty
Toolik_watershed_data <-  Toolik_watershed_data[-c(1, 2, 3),]

```

#Data Cleanup


```{r}

#removing colons and dashes from attribute column names
Toolik_watershed_data$Type <- gsub("[^0-9A-Za-z///' ]","", Toolik_watershed_data$Type)

#removing cation preface
Toolik_watershed_data$Type <- gsub("Cations", "", Toolik_watershed_data$Type)

#strip white space
Toolik_watershed_data$Type  <- trimws(Toolik_watershed_data$Type, which = c("left"))


#Adding a column to identify the LTER site - ARC
Toolik_watershed_data <- Toolik_watershed_data %>% 
  add_column(LTER = 'ARC', .before = "River")

#all watershed except the fog lake series
Toolik_rivers_watershed <- Toolik_watershed_data %>% 
 filter(River %in% c("Birthday Creek", "Burn Reference Streams", "Caterpillar Creek", "Caterpillar Creek TK", "Dimple Inlet", "Dimple Outlet", "I-Minus 2", "I-Minus 2 TK", "Imnavait Creek", "Itkillik Tributary", "Kuparuk River", "North River", "Oksrukuyik Creek", "Roche Moutonnee Creek", "Shrew River", "South River", "South River Trib", "Toolik Inlet","Toolik River", "Toolik River TK", "Toolik River TK-4", "Trevor Creek", "Upper Kuparuk", "VTK IMP", "VTK REF"))

#Unsure what the 'Site/Stream Name' should be so combining river name and station
Toolik_rivers_watershed  <- Toolik_rivers_watershed  %>% 
add_column('Site/Stream Name' = paste(Toolik_rivers_watershed$River, Toolik_rivers_watershed$Station), .before = 'River')

```

```{r}

#distinct df that highlights the duplicates
Toolik_watershed_with_duplicates <- pivot_wider(Toolik_rivers_watershed, names_from = 'Type', values_from = 'Value')

#cleaning up duplicates file to share
Toolik_watershed_with_duplicates   <- Toolik_watershed_with_duplicates %>% 
  select(-'Site Code', -'Station', -'Reach', -'Method / Instrument', -'Units', -'River')  %>% 
  rename('Sampling Date' = 'Date')


#extracting 'time' from sampling date column and making it it's own column
Toolik_watershed_with_duplicates   <- add_column(.data = Toolik_watershed_with_duplicates, 'Time' = substr(Toolik_watershed_with_duplicates$`Sampling Date`, 11, 16), .after = 'Sampling Date')

#removing time from sampling date column
Toolik_watershed_with_duplicates  <- Toolik_watershed_with_duplicates %>% 
  mutate('Sampling Date' = substr(Toolik_watershed_with_duplicates$`Sampling Date`, 1, 10))

#Renaming columns to match template abbreviations
Toolik_watershed_with_duplicates <- Toolik_watershed_with_duplicates  %>% 
  rename('Ca' = 'Calcium', 'Spec Cond' = 'Specific Conductivity', 'Na' = 'Sodium', 'K' = 'Potassium', 'Mg' = 'Magnesium', 'TDP' = 'Total Dissolved Phosphorus', 'DOC' = 'Dissolved Organic Carbon', 'NH4' = 'Ammonium', 'TDN' = 'Total Dissolved Nitrogen', 'Suspended Chl' = 'Sestonic Total Chlorophyll', 'Temp C' = 'Temp when sample collected', 'SRP' = 'Soluble Reactive Phosphorus', 'Cl' = 'Chloride', 'alkalinity' = 'Alkalinity', 'Pb' = 'Lead', 'Fe' = 'Iron', 'SO4' = 'Sulfate', 'Cu' = 'Copper', 'TSS' = 'Total Suspended Sediment', 'CO2' = 'Carbon Dioxide', 'DIC' = 'Dissolved Inorganic Carbon', 'CH4' = 'Methane')



Toolik_watershed_with_duplicates2 <- Toolik_watershed_with_duplicates %>% 
filter(str_detect(alkalinity, pattern = ",")) %>% 


Toolik_watershed_with_duplicates3 = sapply(Toolik_watershed_with_duplicates[6:20],
              function(x) grep(",", x, value = TRUE))


attributes_with_duplicates <- names(Toolik_watershed_with_duplicates3)

```
Alkalinity

```{r}


Toolik_watershed_with_duplicates4 <- Toolik_watershed_with_duplicates %>% 
  separate(alkalinity, c("A", "B", "C"),sep=",")  %>%
  mutate(alkalinity = mean("A", "B", "C")) 

Toolik_watershed_with_duplicates4$alkalinity <- ifelse(is.na(Toolik_watershed_with_duplicates4$alkalinity), Toolik_watershed_with_duplicates4$A, Toolik_watershed_with_duplicates4$alkalinity) 


```

```{r}





```




Read in template. Doulbe check the template is correct!
```{r}

template <- read_excel(here("metajam_example", "Raw stream data template.xlsx"), 
                               col_types = "text"
                               ) %>%
  mutate(`Sampling Date` = as.Date(`Sampling Date`))  %>% 
  add_column('Comments' = ' ')

```

Fuzzy Match
```{r}


# Start by matching by closest name as a first pass. 
  # Note that we match the lower case names
  # Note that the weight i= 0.1 says that we will be more likely to match if watershed 1 = template + extra
(fuzzy_match <- tibble(template = names(template)) %>%
   mutate(watershed_toolik_all = names(Toolik_watershed_with_duplicates4)[amatch(tolower(template), tolower(names(Toolik_watershed_with_duplicates4)), maxDist = 1, weight = c(d=1,i=0.1,s=1,t=1))])
)

```